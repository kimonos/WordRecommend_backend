package com.example.wordrecommend_backend.service;

import com.example.wordrecommend_backend.dto.WordDTO;
import com.example.wordrecommend_backend.entity.*;
import com.example.wordrecommend_backend.repository.ReviewHistoryRepository;
import com.example.wordrecommend_backend.repository.WordRepository;
import com.example.wordrecommend_backend.repository.WordStateRepository;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.data.domain.PageRequest;
import org.springframework.data.domain.Pageable;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

import java.time.LocalDateTime;
import java.util.*;
import java.util.function.Supplier;
import java.util.stream.Collectors;

@Service
@RequiredArgsConstructor
@Slf4j
public class RecommendationService {

    private final WordRepository wordRepository;
    private final WordStateRepository wordStateRepository;
    private final ReviewHistoryRepository reviewHistoryRepository;
    private final AlgorithmCoreService algorithmCoreService;

    // ==================== å…¬é–‹æ–¹æ³•ï¼šæ¨è–¦å–®å­—ï¼ˆv2.0 - Phase 5ï¼‰====================

    /**
     * æ ¸å¿ƒæ–¹æ³•ï¼šç‚ºä½¿ç”¨è€…æ¨è–¦å–®å­—ï¼ˆv2.0 - è¼•é‡ç‰ˆï¼‰
     *
     * è¨­è¨ˆç†å¿µï¼š
     * - æ¢ç´¢ç‚ºä¸»ï¼ˆæ–°å–®å­—ç‚ºä¸»ï¼‰
     * - å­¸ç¿’é–‰ç’°ï¼ˆé©é‡èˆŠå–®å­—ï¼‰
     * - éºå¿˜æé†’ï¼ˆS-1 å–®å­—è¼•åº¦æé†’ï¼‰
     * - å‹•æ…‹èª¿æ•´ï¼ˆæ ¹æ“šæ–°å–®å­—å‰©é¤˜é‡ï¼‰
     *
     * @param user ç›®æ¨™ä½¿ç”¨è€…
     * @param limit éœ€è¦æ¨è–¦çš„å–®å­—æ•¸é‡
     * @return æ¨è–¦çš„å–®å­—åˆ—è¡¨ï¼ˆåŒ…å«ç‹€æ…‹è³‡è¨Šï¼‰
     */
    @Transactional(readOnly = true)
    public List<WordDTO> getWordRecommendations(User user, int limit) {
        if (limit <= 0) return Collections.emptyList();

        LocalDateTime currentTime = LocalDateTime.now();

        // ========== æ­¥é©Ÿ 1ï¼šçµ±è¨ˆä½¿ç”¨è€…çš„å­¸ç¿’ç‹€æ…‹ ==========
        long countS_1 = wordStateRepository.countForgottenWords(user);
        long countS1 = wordStateRepository.countByUserAndState(user, "S1");
        long countS2 = wordStateRepository.countByUserAndState(user, "S2");
        long countS3 = wordStateRepository.countByUserAndState(user, "S3");
        double totalLearned = countS_1 + countS1 + countS2 + countS3;

        log.info("User {} learning stats: S-1={}, S1={}, S2={}, S3={}, total={}",
                user.getId(), countS_1, countS1, countS2, countS3, totalLearned);

        // ========== æ­¥é©Ÿ 2ï¼šæ ¹æ“šå­¸ç¿’é€²åº¦å’Œæ–°å–®å­—å‰©é¤˜é‡æ±ºå®šç‹€æ…‹æ¯”ä¾‹ ==========
        Map<String, Double> stateRatio = new LinkedHashMap<>();

        if (totalLearned < 50) {
            // æ–°æ‰‹éšæ®µï¼š100% æ¨è–¦æ–°å–®å­—
            stateRatio.put("S0", 1.0);
            stateRatio.put("S-1", 0.0);
            stateRatio.put("S1", 0.0);
            stateRatio.put("S2", 0.0);
            stateRatio.put("S3", 0.0);

            log.debug("Beginner mode: 100% new words");

        } else {
            // é€²éšéšæ®µï¼šæ ¹æ“šæ–°å–®å­—å‰©é¤˜é‡å‹•æ…‹èª¿æ•´

            // ğŸ”‘ æŸ¥è©¢æ–°å–®å­—å‰©é¤˜æ•¸é‡ï¼ˆç²¾ç¢ºæŸ¥è©¢ï¼‰
            long availableNewWords = wordRepository.countNewWords(user);

            log.info("User {} has {} new words available (out of total learned: {})",
                    user.getId(), availableNewWords, (long)totalLearned);

            // ğŸ”‘ é—œéµåˆ¤æ–·ï¼šæ–°å–®å­—æ˜¯å¦å®Œå…¨è€—ç›¡
            if (availableNewWords == 0) {
                // ========== æƒ…å¢ƒ Dï¼šæ–°å–®å­—å®Œå…¨è€—ç›¡ - ç´”è¤‡ç¿’æ¨¡å¼ ==========
                stateRatio.put("S0", 0.0);   // 0% æ–°å–®å­—
                stateRatio.put("S-1", 0.20); // å„ªå…ˆå¾©åŸéºå¿˜å–®å­—
                stateRatio.put("S1", 0.35);  // è¤‡ç¿’ä¸ç†Ÿçš„
                stateRatio.put("S2", 0.30);  // è¤‡ç¿’ä¸­ç­‰çš„
                stateRatio.put("S3", 0.15);  // ç¶­æŒç²¾é€šçš„

                log.info("Strategy: Pure Review Mode (no new words available)");

            } else {
                // é‚„æœ‰æ–°å–®å­—ï¼Œæ ¹æ“šå‰©é¤˜æ¯”ä¾‹å‹•æ…‹èª¿æ•´
                double newWordRatio = (double)availableNewWords / (totalLearned + availableNewWords);

                log.debug("New word ratio: {:.2f}%", newWordRatio * 100);

                double s1Ratio = (countS_1 > 0) ? 0.05 : 0.0;

                if (newWordRatio > 0.5) {
                    // ========== æƒ…å¢ƒ Aï¼šæ–°å–®å­—å……è¶³ï¼ˆ>50%ï¼‰- æ¢ç´¢ç‚ºä¸» ==========
                    stateRatio.put("S0", 0.60);
                    stateRatio.put("S-1", s1Ratio);
                    stateRatio.put("S1", 0.15);
                    stateRatio.put("S2", 0.15);
                    stateRatio.put("S3", 0.05);

                    log.debug("Strategy: Exploration (60% new words)");

                } else if (newWordRatio > 0.2) {
                    // ========== æƒ…å¢ƒ Bï¼šæ–°å–®å­—æ¸›å°‘ï¼ˆ20-50%ï¼‰- å¹³è¡¡æ¨¡å¼ ==========
                    stateRatio.put("S0", 0.40);
                    stateRatio.put("S-1", Math.max(s1Ratio, 0.10));
                    stateRatio.put("S1", 0.20);
                    stateRatio.put("S2", 0.20);
                    stateRatio.put("S3", 0.10);

                    log.debug("Strategy: Balanced (40% new words)");

                } else {
                    // ========== æƒ…å¢ƒ Cï¼šæ–°å–®å­—ç¨€å°‘ï¼ˆ<20%ï¼‰- è¤‡ç¿’ç‚ºä¸»ä½†ä¿ç•™æ¢ç´¢ ==========
                    // ğŸ”‘ å‹•æ…‹è¨ˆç®—æ–°å–®å­—æ¯”ä¾‹ï¼ˆç¢ºä¿æ‰€æœ‰æ–°å–®å­—éƒ½æœ‰æ©Ÿæœƒè¢«å­¸åˆ°ï¼‰
                    double newRatio = Math.max(0.15, Math.min(0.30, newWordRatio * 1.5));

                    stateRatio.put("S0", newRatio);
                    stateRatio.put("S-1", 0.15);
                    stateRatio.put("S1", (1 - newRatio - 0.15) * 0.45);
                    stateRatio.put("S2", (1 - newRatio - 0.15) * 0.40);
                    stateRatio.put("S3", (1 - newRatio - 0.15) * 0.15);

                    log.debug("Strategy: Review-focused ({:.1f}% new words, {} available)",
                            newRatio * 100, availableNewWords);
                }
            }
        }

        // ========== æ­¥é©Ÿ 3ï¼šåˆ†é…å„ç‹€æ…‹çš„é…é¡ ==========
        Map<String, Integer> stateCounts = distributeCounts(limit, stateRatio);
        int numS0 = stateCounts.getOrDefault("S0", 0);
        int numS_1 = stateCounts.getOrDefault("S-1", 0);
        int numS1 = stateCounts.getOrDefault("S1", 0);
        int numS2 = stateCounts.getOrDefault("S2", 0);
        int numS3 = stateCounts.getOrDefault("S3", 0);

        log.debug("Quota allocation: S0={}, S-1={}, S1={}, S2={}, S3={}",
                numS0, numS_1, numS1, numS2, numS3);

        // ========== æ­¥é©Ÿ 4ï¼šå‹•æ…‹èª¿æ•´ S0 æ–°å–®å­—çš„é›£åº¦ç­‰ç´šæ¯”ä¾‹ ==========
        double progress = sigmoid(totalLearned, 750.0, 0.02);
        Map<String, Double> levelRatio = new LinkedHashMap<>();
        levelRatio.put("A1", 0.30 - 0.20 * progress);
        levelRatio.put("A2", 0.25 - 0.15 * progress);
        levelRatio.put("B1", 0.20 - 0.05 * progress);
        levelRatio.put("B2", 0.15 - 0.05 * progress);
        levelRatio.put("C1", 0.07 + 0.25 * progress);
        levelRatio.put("C2", 0.03 + 0.20 * progress);

        Map<String, Integer> s0LevelCounts = distributeCounts(numS0, levelRatio);

        // ========== æ­¥é©Ÿ 5ï¼šå¾è³‡æ–™åº«å–å‡ºå„é¡å–®å­— ==========

        // 5.1 å– S0 æ–°å–®å­—ï¼ˆæŒ‰é›£åº¦ç­‰ç´šåˆ†åˆ¥å–ï¼Œéš¨æ©Ÿæ’åºï¼‰
        List<Word> s0Words = new ArrayList<>();
        for (Map.Entry<String, Integer> e : s0LevelCounts.entrySet()) {
            int take = e.getValue();
            if (take <= 0) continue;
            s0Words.addAll(wordRepository.findNewWordsByLevel(user, e.getKey(), page(take)));
        }

        // 5.2 å– S-1 å–®å­—ï¼ˆéºå¿˜å–®å­—ï¼Œè¼•åº¦å„ªå…ˆåº¦æ’åºï¼‰
        List<Word> s_1Words = fetchWordsWithPriority(
                user, "S-1", numS_1, currentTime,
                () -> wordStateRepository.findForgottenWords(user, PageRequest.of(0, Math.max(numS_1 * 2, 10)))
        );

        // 5.3 å– S1 å–®å­—ï¼ˆè¼•åº¦å„ªå…ˆåº¦æ’åºï¼‰
        List<Word> s1Words = fetchWordsWithPriority(
                user, "S1", numS1, currentTime,
                () -> wordStateRepository.findByUserAndState(user, "S1", PageRequest.of(0, Math.max(numS1 * 2, 10)))
        );

        // 5.4 å– S2 å–®å­—ï¼ˆè¼•åº¦å„ªå…ˆåº¦æ’åºï¼‰
        List<Word> s2Words = fetchWordsWithPriority(
                user, "S2", numS2, currentTime,
                () -> wordStateRepository.findByUserAndState(user, "S2", PageRequest.of(0, Math.max(numS2 * 2, 10)))
        );

        // 5.5 å– S3 å–®å­—ï¼ˆéš¨æ©Ÿå³å¯ï¼Œå·²ç²¾é€šï¼‰
        List<Word> s3Words = new ArrayList<>();
        if (numS3 > 0) {
            s3Words = wordStateRepository.findByUserAndState(user, "S3", page(numS3))
                    .stream()
                    .map(WordState::getWord)
                    .collect(Collectors.toList());
        }

        // ========== æ­¥é©Ÿ 6ï¼šåˆä½µæ‰€æœ‰å–®å­—ä¸¦å»é‡ ==========
        List<Word> merged = new ArrayList<>(
                s0Words.size() + s_1Words.size() + s1Words.size() + s2Words.size() + s3Words.size()
        );
        merged.addAll(s0Words);
        merged.addAll(s_1Words);
        merged.addAll(s1Words);
        merged.addAll(s2Words);
        merged.addAll(s3Words);

        List<Word> deduped = deduplicateById(merged);

        // ========== æ­¥é©Ÿ 6.5ï¼šæ™ºèƒ½éè£œï¼ˆå¦‚æœæ•¸é‡ä¸è¶³ï¼‰==========
        if (deduped.size() < limit) {
            int missing = limit - deduped.size();
            log.warn("Insufficient words: got {}, need {}, missing {}",
                    deduped.size(), limit, missing);

            // ğŸ”‘ éè£œç­–ç•¥ï¼šå„ªå…ˆé †åº
            // 1. æ–°å–®å­—ï¼ˆå¦‚æœé‚„æœ‰ï¼‰
            // 2. S-1 éºå¿˜å–®å­—
            // 3. S1 ä¸ç†Ÿçš„å–®å­—
            // 4. S2 è¤‡ç¿’ä¸­çš„å–®å­—
            // 5. S3 ç²¾é€šçš„å–®å­—

            // å˜—è©¦ 1ï¼šè£œå……æ–°å–®å­—
            if (missing > 0) {
                List<Word> extraNewWords = wordRepository.findNewWordsRandomly(user, page(missing * 2));
                for (Word w : extraNewWords) {
                    if (deduped.stream().noneMatch(x -> Objects.equals(x.getId(), w.getId()))) {
                        deduped.add(w);
                        missing--;
                        if (missing == 0) break;
                    }
                }
                log.debug("After adding new words: {} words, missing {}", deduped.size(), missing);
            }

            // å˜—è©¦ 2ï¼šè£œå…… S-1 éºå¿˜å–®å­—
            if (missing > 0 && countS_1 > 0) {
                List<WordState> extraS_1 = wordStateRepository.findForgottenWords(
                        user, PageRequest.of(0, missing * 2)
                );
                for (WordState ws : extraS_1) {
                    Word w = ws.getWord();
                    if (deduped.stream().noneMatch(x -> Objects.equals(x.getId(), w.getId()))) {
                        deduped.add(w);
                        missing--;
                        if (missing == 0) break;
                    }
                }
                log.debug("After adding S-1 words: {} words, missing {}", deduped.size(), missing);
            }

            // å˜—è©¦ 3ï¼šè£œå…… S1 å–®å­—
            if (missing > 0 && countS1 > 0) {
                List<WordState> extraS1 = wordStateRepository.findByUserAndState(
                        user, "S1", PageRequest.of(0, missing * 2)
                );
                for (WordState ws : extraS1) {
                    Word w = ws.getWord();
                    if (deduped.stream().noneMatch(x -> Objects.equals(x.getId(), w.getId()))) {
                        deduped.add(w);
                        missing--;
                        if (missing == 0) break;
                    }
                }
                log.debug("After adding S1 words: {} words, missing {}", deduped.size(), missing);
            }

            // å˜—è©¦ 4ï¼šè£œå…… S2 å–®å­—
            if (missing > 0 && countS2 > 0) {
                List<WordState> extraS2 = wordStateRepository.findByUserAndState(
                        user, "S2", PageRequest.of(0, missing * 2)
                );
                for (WordState ws : extraS2) {
                    Word w = ws.getWord();
                    if (deduped.stream().noneMatch(x -> Objects.equals(x.getId(), w.getId()))) {
                        deduped.add(w);
                        missing--;
                        if (missing == 0) break;
                    }
                }
                log.debug("After adding S2 words: {} words, missing {}", deduped.size(), missing);
            }

            // å˜—è©¦ 5ï¼šè£œå…… S3 å–®å­—ï¼ˆæœ€å¾Œæ‰‹æ®µï¼‰
            if (missing > 0 && countS3 > 0) {
                List<WordState> extraS3 = wordStateRepository.findByUserAndState(
                        user, "S3", PageRequest.of(0, missing * 2)
                );
                for (WordState ws : extraS3) {
                    Word w = ws.getWord();
                    if (deduped.stream().noneMatch(x -> Objects.equals(x.getId(), w.getId()))) {
                        deduped.add(w);
                        missing--;
                        if (missing == 0) break;
                    }
                }
                log.debug("After adding S3 words: {} words, missing {}", deduped.size(), missing);
            }

            if (missing > 0) {
                log.warn("Still missing {} words after all fallback attempts", missing);
            } else {
                log.info("Successfully filled to {} words", deduped.size());
            }
        }

        // åš´æ ¼æˆªæ–·è‡³ limit
        if (deduped.size() > limit) {
            deduped = new ArrayList<>(deduped.subList(0, limit));
        }

        // ========== æ­¥é©Ÿ 7ï¼šç‚ºæ¯å€‹å–®å­—æ¨™è¨˜ç‹€æ…‹ï¼Œä¸¦è½‰æ›æˆ DTO ==========
        Map<Long, String> stateMap = new HashMap<>();
        s0Words.forEach(w -> stateMap.put(w.getId(), "S0"));
        s_1Words.forEach(w -> stateMap.put(w.getId(), "S-1"));
        s1Words.forEach(w -> stateMap.put(w.getId(), "S1"));
        s2Words.forEach(w -> stateMap.put(w.getId(), "S2"));
        s3Words.forEach(w -> stateMap.put(w.getId(), "S3"));
        deduped.forEach(w -> stateMap.putIfAbsent(w.getId(), "S0"));

        // éš¨æ©Ÿæ‰“äº‚é †åºï¼ˆä¿æŒæ¢ç´¢æ¨‚è¶£ï¼‰
        Collections.shuffle(deduped);

        log.info("Final recommendation for user {}: {} words (S0={}, S-1={}, S1={}, S2={}, S3={})",
                user.getId(), deduped.size(),
                s0Words.size(), s_1Words.size(), s1Words.size(), s2Words.size(), s3Words.size());

        return deduped.stream()
                .map(w -> WordDTO.fromEntityWithState(w, stateMap.getOrDefault(w.getId(), "S0")))
                .collect(Collectors.toList());
    }

    // ==================== å…¬é–‹æ–¹æ³•ï¼šé–±è®€è™•ç†ï¼ˆPhase 6ï¼‰====================

    /**
     * è™•ç†é–±è®€äº‹ä»¶ï¼ˆv2.0ï¼‰
     *
     * æ¥­å‹™é‚è¼¯ï¼š
     * - èª¿ç”¨ Phase 3 é–±è®€ç®—æ³•
     * - è¨˜æ†¶å¢ç›Šè¼ƒå°ï¼ˆÎ”M = 0.01 ~ 0.05ï¼‰
     * - æ¬¡æ•¸è¡°æ¸›æ•ˆæœï¼ˆåè¦†é–±è®€å¢ç›Šéæ¸›ï¼‰
     *
     * @param user ä½¿ç”¨è€…
     * @param wordId å–®å­— ID
     * @param durationSeconds é–±è®€æ™‚é•·ï¼ˆç§’ï¼‰
     * @return æ›´æ–°å¾Œçš„ WordState
     */
    @Transactional
    public WordState handleReadingEvent(User user, Long wordId, double durationSeconds) {

        // ğŸ”‘ æ·»åŠ å”¯ä¸€è«‹æ±‚ ID
        String requestId = UUID.randomUUID().toString().substring(0, 8);

        log.info("ğŸŸ¢ [{}] handleReadingEvent START: user={}, wordId={}, duration={}s",
                requestId, user.getId(), wordId, durationSeconds);

        // ========== æ­¥é©Ÿ 1ï¼šæŸ¥è©¢å–®å­—å’Œç‹€æ…‹ ==========
        Word word = wordRepository.findById(wordId)
                .orElseThrow(() -> {
                    log.error("ğŸ”´ [{}] Word not found: wordId={}", requestId, wordId);
                    return new RuntimeException("Word not found: " + wordId);
                });

        log.debug("ğŸŸ¢ [{}] Word found: {}", requestId, word.getWordText());

        WordState state = wordStateRepository.findByUserAndWord(user, word)
                .orElseGet(() -> {
                    log.debug("ğŸŸ¢ [{}] WordState not found, initializing new state", requestId);
                    return initializeNewState(user, word);
                });

        log.debug("ğŸŸ¢ [{}] Current state: {}, strength: {}, readCount: {}",
                requestId, state.getCurrentState(), state.getMemoryStrength(), state.getReadCount());

        LocalDateTime now = LocalDateTime.now();

        // ========== æ­¥é©Ÿ 2ï¼šè¨˜éŒ„é–±è®€å‰çš„ç‹€æ…‹ ==========
        String previousState = state.getCurrentState();
        double previousStrength = state.getMemoryStrength();
        int previousReadCount = state.getReadCount();
        boolean prevEver = Boolean.TRUE.equals(state.getHasEverLearned());

        // ========== æ­¥é©Ÿ 3ï¼šèª¿ç”¨ Phase 3 é–±è®€ç®—æ³• ==========
        double newStrength = algorithmCoreService.calculateNewMemoryStrengthFromReading(
                state, word, durationSeconds, now
        );

        log.debug("ğŸŸ¢ [{}] Memory strength: {:.3f} â†’ {:.3f}",
                requestId, previousStrength, newStrength);

        // ========== æ­¥é©Ÿ 4ï¼šåˆ¤å®šæ–°çš„ FSM ç‹€æ…‹ ==========
        String newState = algorithmCoreService.determineFsmState(
                newStrength,
                state.getHasEverLearned()
        );

        log.debug("ğŸŸ¢ [{}] FSM state: {} â†’ {}", requestId, previousState, newState);

        if ("S0".equals(previousState)) {
            newState = "S1";
            if (!Boolean.TRUE.equals(state.getHasEverLearned())) {
                state.setHasEverLearned(true);
            }
            log.info("ğŸŸ¢ [{}] Promote by reading: S0 â†’ S1, hasEverLearned set to true", requestId);
        }

        // ========== æ­¥é©Ÿ 5ï¼šæ›´æ–° WordState çš„æ ¸å¿ƒæ¬„ä½ ==========
        state.setMemoryStrength(newStrength);
        state.setCurrentState(newState);
        state.setLastReviewTime(now);
        state.setLastReadTime(now);

        // ========== æ­¥é©Ÿ 6ï¼šæ›´æ–°é–±è®€çµ±è¨ˆ ==========
        int newCount = state.getReadCount() + 1;
        state.setReadCount(newCount);

        double newTotal = state.getTotalReadDuration() + durationSeconds;
        state.setTotalReadDuration(newTotal);

        double newAvg = newTotal / newCount;
        state.setAvgReadDuration(newAvg);

        log.debug("ğŸŸ¢ [{}] Reading statistics: count: {}â†’{}, total: {:.1f}s, avg: {:.1f}s",
                requestId, previousReadCount, newCount, newTotal, newAvg);

        // ========== æ­¥é©Ÿ 7ï¼šä¿å­˜æ­·å²è¨˜éŒ„ ==========
        log.info("ğŸŸ¢ [{}] Saving review history...", requestId);

        ReviewHistory history = new ReviewHistory();
        history.setUser(user);
        history.setWord(word);
        history.setInteractionType(InteractionType.READ);
        history.setReviewTime(now);
        history.setDurationMs((long)(durationSeconds * 1000));
        history.setIsCorrect(null);

        ReviewHistory savedHistory = reviewHistoryRepository.save(history);

        log.info("ğŸŸ¢ [{}] Review history saved: id={}", requestId, savedHistory.getId());

        // ========== æ­¥é©Ÿ 8ï¼šä¿å­˜ä¸¦è¿”å› ==========
        log.info("ğŸŸ¢ [{}] Saving WordState...", requestId);

        WordState saved = wordStateRepository.save(state);

        log.info("ğŸŸ¢ [{}] handleReadingEvent END: word='{}', duration={:.1f}s, " +
                        "strength: {:.3f}â†’{:.3f}, state: {}â†’{}, read_count: {}â†’{}",
                requestId, word.getWordText(), durationSeconds,
                previousStrength, newStrength,
                previousState, newState,
                previousReadCount, newCount);

        return saved;
    }

    // ==================== å…¬é–‹æ–¹æ³•ï¼šå­¸ç¿’çµ±è¨ˆ ====================

    /**
     * ç²å–å­¸ç¿’çµ±è¨ˆæ‘˜è¦
     */
    @Transactional(readOnly = true)
    public Map<String, Object> getLearningStatsSummary(User user) {
        Map<String, Object> stats = new HashMap<>();

        List<Object[]> stateStats = wordStateRepository.countByUserGroupByState(user);

        long totalS0 = 0, totalS_1 = 0, totalS1 = 0, totalS2 = 0, totalS3 = 0;
        for (Object[] row : stateStats) {
            String state = (String) row[0];
            Long count = (Long) row[1];

            switch (state) {
                case "S0":  totalS0 = count; break;
                case "S-1": totalS_1 = count; break;
                case "S1":  totalS1 = count; break;
                case "S2":  totalS2 = count; break;
                case "S3":  totalS3 = count; break;
            }
        }

        stats.put("newWords", totalS0);
        stats.put("forgottenWords", totalS_1);
        stats.put("learningWords", totalS1);
        stats.put("reviewingWords", totalS2);
        stats.put("masteredWords", totalS3);
        stats.put("totalLearned", totalS_1 + totalS1 + totalS2 + totalS3);

        log.debug("Learning stats for user {}: {}", user.getId(), stats);

        return stats;
    }

    // ==================== v2.0 è¼”åŠ©æ–¹æ³• ====================

    /**
     * ä½¿ç”¨è¼•åº¦å„ªå…ˆåº¦æ’åºç²å–å–®å­—
     */
    private List<Word> fetchWordsWithPriority(
            User user,
            String state,
            int targetCount,
            LocalDateTime currentTime,
            Supplier<List<WordState>> fetcher) {

        if (targetCount <= 0) {
            return new ArrayList<>();
        }

        List<WordState> candidates = fetcher.get();

        if (candidates.isEmpty()) {
            log.debug("No {} words found for user {}", state, user.getId());
            return new ArrayList<>();
        }

        if (candidates.size() <= targetCount) {
            log.debug("Limited {} candidates ({}), return all", state, candidates.size());
            return candidates.stream()
                    .map(WordState::getWord)
                    .collect(Collectors.toList());
        }

        Map<Long, Double> priorities = new HashMap<>();
        for (WordState ws : candidates) {
            double priority = algorithmCoreService.calculateReviewPriority(
                    ws, ws.getWord(), currentTime
            );
            priorities.put(ws.getWord().getId(), priority);
        }

        List<WordState> sorted = candidates.stream()
                .sorted((a, b) -> {
                    double priorityA = priorities.getOrDefault(a.getWord().getId(), 0.0);
                    double priorityB = priorities.getOrDefault(b.getWord().getId(), 0.0);
                    return Double.compare(priorityB, priorityA);
                })
                .collect(Collectors.toList());

        int topCount = Math.max((int)(sorted.size() * 0.6), targetCount);
        List<WordState> topPriority = sorted.subList(0, Math.min(topCount, sorted.size()));

        Collections.shuffle(topPriority);

        List<Word> result = topPriority.stream()
                .limit(targetCount)
                .map(WordState::getWord)
                .collect(Collectors.toList());

        log.debug("Selected {} {} words from {} candidates (top 60% then random)",
                result.size(), state, candidates.size());

        return result;
    }

    /**
     * åˆå§‹åŒ–æ–°çš„ WordState
     */
    private WordState initializeNewState(User user, Word word) {
        WordState state = new WordState();

        state.setUser(user);
        state.setWord(word);

        state.setMemoryStrength(0.0);
        state.setCurrentState("S0");
        state.setHasEverLearned(false);

        state.setTotalCorrect(0);
        state.setTotalIncorrect(0);
        state.setAverageResponseTimeMs(0L);

        state.setReadCount(0);
        state.setTotalReadDuration(0.0);
        state.setAvgReadDuration(0.0);

        state.setForgottenCount(0);
        state.setLastForgottenTime(null);

        LocalDateTime now = LocalDateTime.now();
        state.setLastReviewTime(now);
        state.setLastReadTime(null);

        state.setNextReviewPriority(0.0);

        log.debug("Initialized new WordState: user={}, word='{}', state=S0, strength=0.0",
                user.getId(), word.getWordText());

        return state;
    }

    // ==================== åŸæœ‰å·¥å…·æ–¹æ³• ====================

    private Map<String, Integer> distributeCounts(int total, Map<String, Double> ratios) {
        Map<String, Integer> result = new LinkedHashMap<>();

        if (total <= 0 || ratios == null || ratios.isEmpty()) {
            if (ratios != null) ratios.keySet().forEach(k -> result.put(k, 0));
            return result;
        }

        double sum = ratios.values().stream().mapToDouble(Double::doubleValue).sum();

        if (sum <= 0) {
            ratios.keySet().forEach(k -> result.put(k, 0));
            return result;
        }

        class Part {
            String key;
            double frac;
            Part(String k, double f) {
                key = k;
                frac = f;
            }
        }

        List<Part> fracs = new ArrayList<>();
        int allocated = 0;

        for (Map.Entry<String, Double> e : ratios.entrySet()) {
            double exact = total * (e.getValue() / sum);
            int base = (int) Math.floor(exact);
            double rem = exact - base;
            result.put(e.getKey(), base);
            fracs.add(new Part(e.getKey(), rem));
            allocated += base;
        }

        int remain = total - allocated;
        fracs.sort((a, b) -> Double.compare(b.frac, a.frac));

        for (int i = 0; i < remain && i < fracs.size(); i++) {
            String k = fracs.get(i).key;
            result.put(k, result.get(k) + 1);
        }

        return result;
    }

    private Pageable page(int size) {
        return PageRequest.of(0, Math.max(1, size));
    }

    private List<Word> deduplicateById(List<Word> list) {
        Set<Long> seen = new HashSet<>();
        List<Word> out = new ArrayList<>(list.size());

        for (Word w : list) {
            if (w == null || w.getId() == null) continue;
            if (seen.add(w.getId())) {
                out.add(w);
            }
        }

        return out;
    }

    private double sigmoid(double x, double x0, double k) {
        return 1.0 / (1.0 + Math.exp(-k * (x - x0)));
    }
}